# LLM Dataset Curation & Validation Pipeline

Large Language Models are extremely sensitive to the quality of the data they are trained and evaluated on.
Small issues like duplicate samples, data leakage, or schema inconsistencies can lead to misleading metrics
and brittle model behavior.

This project focuses on building a clean, explainable data engineering pipeline for LLM datasets.
The goal is to define what “good data” means, enforce it systematically, and make dataset decisions
transparent and reproducible.
